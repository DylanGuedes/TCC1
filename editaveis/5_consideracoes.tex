\chapter{CONSIDERAÇÕES PRELIMINARES}
\label{chapter:final}

As contribuições deste trabalho propiciaram ao InterSCity a possibilidade de
atuação em cenários mais extremos e abrangentes, por meio de um novo serviço
para processamento de seus dados. Juntamente com o novo serviço, desenvolvemos
uma aplicação que abstrai as ferramentas de \textit{Big Data} utilizadas pelo
projeto, e que fornece meios para que outras aplicações de cidades inteligentes
requisitem tarefas para serem processadas pela plataforma. Com a incorporação
dos resultados que desenvolvemos o InterSCity passa então: a poder atuar em
operações com grande massa de dados; a fornecer processamento de dados para
terceiros através da plataforma; e a possibilitar o uso de algoritmos mais
complexos, como de aprendizado de máquina.

Começamos esta primeira etapa do trabalho em março/2017, e estivemos envolvidos
com a revisão bibliográfica e das técnicas sobre arquiteturas e tecnologias de
\textit{Big Data}, assim como na concepção do serviço de processamento de dados
para o InterSCity. Desta forma, ainda existem várias melhorias a serem feitas na
implementação inicial do Shock, como a resolução de dívidas técnicas e apuração
de maior referencial científico. Portanto, planejamos as seguintes atividades
para a continuação do trabalho:

\begin{itemize}
    \item \textbf{Segunda rodada de revisão na bibliografia}: para termos esta
        proposta e os primeiros resultados em 2 meses, fizemos uma primeira
        rodada de revisão bibliográfica, e entendemos que as tecnologias e
        técnicas utilizadas são recentes, o que não nos trouxe muitas
        referências acadêmicas. Com uma segunda revisão bibliográfica,
        poderemos gerar mais insumos para justificativas e adaptações
        a serem implantadas no InterSCity;

    \item \textbf{Desacoplar o núcleo do Shock do Kafka}: o Shock neste
        momento está acoplado ao Kafka em diversos aspectos, de modo que a
        escrita de testes seja difícil, e impossibilitando o uso de outros
        \textit{streams} no Spark, como o de MQTT;

    \item \textbf{Testar o núcleo do Shock}: por conta do pouco tempo e do
        acoplamento entre o Kafka e o Shock, não desenvolvemos os testes da
        aplicação;

    \item \textbf{Documentar a API de serviços}: por conta da alta volatilidade
        da arquitetura e da API do Shock, não produzimos uma documentação
        completa. Uma melhor documentação ajudará o time do InterSCity a
        prosseguir com o serviço desenvolvido;

    \item \textbf{Utilizar outras estruturas de dados}: atualmente o Shock só
        conta com RDD's, que são estruturas elementares do Spark. A troca por
        outras estruturas, como os Data Frames, pode melhorar a performance e a
        manutenibilidade do serviço;

    \item \textbf{Customização de janelas de \textit{micro-batches}}: o Shock
        utiliza o mesmo tempo de janela de \textit{micro-batch}, independente
        do contexto. Uma customização ajudaria na adaptação do Shock
        em um maior número de contextos, sendo útil inclusive no
        desenvolvimento de testes;

    \item \textbf{Múltiplos \textit{streams}}: o Shock só utiliza os
        \textit{streams} do Kafka, e sempre um \textit{stream} único. Com
        múltiplos \textit{streams} seria possível ter múltiplos \textit{
        pipeline de dados}, interessante para as aplicações que utilizam
        a plataforma;

    \item \textbf{Controle de \textit{check-point}}: o controle de
        \textit{check-points} adicionará maior tolerância ao Shock em caso
        de falhas graves, diminuindo os pontos de ruptura;

    \item \textbf{Utilizar \textit{log} do Kafka}: a utilização do \textit{log}
        do Kafka possibilitará a recuperação de dados históricos;

    \item \textbf{Introduzir o Shock ao \textit{core} do InterSCity}: o Shock
        não está em um estado estável o suficiente para fazer parte do
        InterSCity. Quando o Shock estiver nesse nível de estabilidade, ele
        poderá finalmente fazer parte do núcleo da plataforma.
\end{itemize}

Planejamos algumas das pendências do novo serviço de processamento
para serem resolvidas no TCC 2, conforme o cronograma apresentado na Tabela
\ref{tab:cronograma}.

\begin{table}[h]
  \begin{center}
  \caption{Cronograma com o planejamento das dívidas técnicas para o TCC 2.}
      \label{tab:cronograma}
    \begin{tabular}{|l| p{12cm}|c|}
        \hline \textbf{Mês} & \textbf{Atividade}  & \textbf{Esforço} \\

        \hline Maio & Revisão mais profunda na bibliografia a respeito das
        tecnologias e arquiteturas no contexto de cidades inteligentes. &
        Alto \\

        \hline Maio & Desacoplar o núcleo do Shock do Kafka. & Médio \\

        \hline Maio e Junho & Testar o núcleo do Shock. & Alto \\

        \hline Maio e Junho & Documentar a API de serviços. & Baixo \\

        \hline Junho & Disponibilizar customização de janelas de \textit{micro-batch}. & Baixo \\

        \hline Julho & Utilizar recuperação de dados históricos através dos
        \textit{logs} do Kafka. & Médio \\

        \hline Julho & Agregar o novo serviço de processamento e as mudanças
        necessárias para o núcleo do InterSCity. & Médio \\

        \hline Julho & Apresentar segunda etapa do trabalho. & - \\

      \hline
    \end{tabular}
  \end{center}
\end{table}

Definimos pendências de menor prioridade para serem resolvidas após o TCC, e
estão apresentadas na Tabela \ref{tab:apos}.

\begin{table}[h]
  \begin{center}
  \caption{Atividades para serem feitas após o TCC.}
  \label{tab:apos}
    \begin{tabular}{|p{12cm}|c|}
        \hline \textbf{Atividade}  & \textbf{Esforço} \\

        \hline Utilizar Data Frames e outras estruturas de dados do
        Spark, e não só RDD's. & Médio \\

        \hline Permitir múltiplos \textit{streams} através da mesma
        API (possibilitando o uso do Kinesis, HDFS, Sockets, entre outros).
          & Alto \\

        \hline Adicionar o controle de \textit{check-points}. 
            & Médio \\

      \hline
    \end{tabular}
  \end{center}
\end{table}
